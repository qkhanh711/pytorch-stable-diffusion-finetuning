{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade calflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 19:19:25.928010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-15 19:19:26.718241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import model_loader\n",
    "from transformers import CLIPTokenizer\n",
    "\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "ALLOW_CUDA = True\n",
    "ALLOW_MPS = False\n",
    "\n",
    "if torch.cuda.is_available() and ALLOW_CUDA:\n",
    "    DEVICE = \"cuda\"\n",
    "elif (torch.has_mps or torch.backends.mps.is_available()) and ALLOW_MPS:\n",
    "    DEVICE = \"mps\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "tokenizer = CLIPTokenizer(\"../../data/vocab.json\", merges_file=\"../../data/merges.txt\")\n",
    "model_file = \"../../data/v1-5-pruned-emaonly.ckpt\"\n",
    "models = model_loader.preload_models_from_standard_weights(model_file, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['clip', 'encoder', 'decoder', 'diffusion'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models[\"encoder\"].to(DEVICE)\n",
    "decoder = models[\"decoder\"].to(DEVICE)\n",
    "clip = models[\"clip\"].to(DEVICE)\n",
    "diffusion = models[\"diffusion\"].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(encoder.VAE_Encoder, decoder.VAE_Decoder, clip.CLIP, diffusion.Diffusion)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoder), type(decoder), type(clip), type(diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "prompt = \"A trafic sign on a beautiful beach.\"\n",
    "uncond_prompt = \"\"  # Also known as negative prompt\n",
    "do_cfg = True\n",
    "cfg_scale = 8  # min: 1, max: 14\n",
    "\n",
    "## IMAGE TO IMAGE\n",
    "\n",
    "# Comment to disable image to image\n",
    "image_path = \"../../images/dog.png\"\n",
    "input_image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rescale, get_time_embedding\n",
    "from config import WIDTH, HEIGHT, LATENTS_WIDTH, LATENTS_HEIGHT\n",
    "from ddpm import DDPMSampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_tokens = tokenizer.batch_encode_plus(\n",
    "    [prompt], padding=\"max_length\", max_length=77\n",
    ")[\"input_ids\"]\n",
    "# (Batch_Size, Seq_Len)\n",
    "cond_tokens = torch.tensor(cond_tokens, dtype=torch.long, device=DEVICE)\n",
    "# (Batch_Size, Seq_Len) -> (Batch_Size, Seq_Len, Dim)\n",
    "cond_context = clip(cond_tokens)\n",
    "# Convert into a list of length Seq_Len=77\n",
    "uncond_tokens = tokenizer.batch_encode_plus(\n",
    "    [uncond_prompt], padding=\"max_length\", max_length=77\n",
    ")[\"input_ids\"]\n",
    "# (Batch_Size, Seq_Len)\n",
    "uncond_tokens = torch.tensor(uncond_tokens, dtype=torch.long, device=DEVICE)\n",
    "# (Batch_Size, Seq_Len) -> (Batch_Size, Seq_Len, Dim)\n",
    "uncond_context = clip(uncond_tokens)\n",
    "# (Batch_Size, Seq_Len, Dim) + (Batch_Size, Seq_Len, Dim) -> (2 * Batch_Size, Seq_Len, Dim)\n",
    "context = torch.cat([cond_context, uncond_context])\n",
    "\n",
    "timestep = 1 \n",
    "time_embedding = get_time_embedding(timestep).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=DEVICE)\n",
    "strength = 0.48\n",
    "n_inference_steps = 50\n",
    "sampler = DDPMSampler(generator)\n",
    "sampler.set_inference_timesteps(n_inference_steps)\n",
    "\n",
    "latents_shape = (1, 4, LATENTS_HEIGHT, LATENTS_WIDTH)\n",
    "\n",
    "encoder = encoder\n",
    "encoder.to(DEVICE)\n",
    "input_image_tensor = input_image.resize((WIDTH, HEIGHT))\n",
    "input_image_tensor = np.array(input_image_tensor)\n",
    "input_image_tensor = torch.tensor(input_image_tensor, dtype=torch.float32, device=DEVICE)\n",
    "input_image_tensor = rescale(input_image_tensor, (0, 255), (-1, 1))\n",
    "input_image_tensor = input_image_tensor.unsqueeze(0)\n",
    "input_image_tensor = input_image_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "encoder_noise = torch.randn(latents_shape, generator=generator, device=DEVICE)\n",
    "latents = encoder(input_image_tensor, encoder_noise)\n",
    "\n",
    "sampler.set_strength(strength=strength)\n",
    "latents = sampler.add_noise(latents, sampler.timesteps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanhhiep/anaconda3/envs/qkhanh/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2923: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  123.06 M\n",
      "fwd MACs:                                                               6.65 GMACs\n",
      "fwd FLOPs:                                                              13.31 GFLOPS\n",
      "fwd+bwd MACs:                                                           19.95 GMACs\n",
      "fwd+bwd FLOPs:                                                          39.92 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "CLIP(\n",
      "  123.06 M = 100% Params, 6.65 GMACs = 100% MACs, 13.31 GFLOPS = 100% FLOPs\n",
      "  (embedding): CLIPEmbedding(\n",
      "    38 M = 30.88% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs\n",
      "    (token_embedding): Embedding(37.95 M = 30.83% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 49408, 768)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-11): 12 x CLIPLayer(\n",
      "      7.09 M = 5.76% Params, 554.1 MMACs = 8.33% MACs, 1.11 GFLOPS = 8.33% FLOPs\n",
      "      (layernorm_1): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 295.68 KFLOPS = 0% FLOPs, (768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attention): SelfAttention(\n",
      "        2.36 M = 1.92% Params, 190.77 MMACs = 2.87% MACs, 381.62 MFLOPS = 2.87% FLOPs\n",
      "        (in_proj): Linear(1.77 M = 1.44% Params, 136.25 MMACs = 2.05% MACs, 272.5 MFLOPS = 2.05% FLOPs, in_features=768, out_features=2304, bias=True)\n",
      "        (out_proj): Linear(590.59 K = 0.48% Params, 45.42 MMACs = 0.68% MACs, 90.83 MFLOPS = 0.68% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (layernorm_2): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 295.68 KFLOPS = 0% FLOPs, (768,), eps=1e-05, elementwise_affine=True)\n",
      "      (linear_1): Linear(2.36 M = 1.92% Params, 181.67 MMACs = 2.73% MACs, 363.33 MFLOPS = 2.73% FLOPs, in_features=768, out_features=3072, bias=True)\n",
      "      (linear_2): Linear(2.36 M = 1.92% Params, 181.67 MMACs = 2.73% MACs, 363.33 MFLOPS = 2.73% FLOPs, in_features=3072, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layernorm): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 295.68 KFLOPS = 0% FLOPs, (768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      " CLIPTokenizer FLOPS: 13.31 GFLOPS, MACs: 6.65 GMACs, Params: 123.06 M\n"
     ]
    }
   ],
   "source": [
    "from calflops import calculate_flops\n",
    "batch_size = 1\n",
    "max_seq_length = 77\n",
    "flops, macs, params = calculate_flops(model=clip, \n",
    "                                    input_shape=(batch_size, max_seq_length),\n",
    "                                    transformer_tokenizer=tokenizer)\n",
    "\n",
    "print(f\" CLIPTokenizer FLOPS: {flops}, MACs: {macs}, Params: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  34.16 M \n",
      "fwd MACs:                                                               558.329 GMACs\n",
      "fwd FLOPs:                                                              1.1185 TFLOPS\n",
      "fwd+bwd MACs:                                                           1.675 TMACs\n",
      "fwd+bwd FLOPs:                                                          3.3554 TFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "VAE_Encoder(\n",
      "  34.16 M = 100% Params, 558.33 GMACs = 100% MACs, 1.12 TFLOPS = 100% FLOPs\n",
      "  (0): Conv2d(3.58 K = 0.0105% Params, 905.97 MMACs = 0.1623% MACs, 1.85 GFLOPS = 0.165% FLOPs, 3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): VAE_ResidualBlock(\n",
      "    295.68 K = 0.8655% Params, 77.31 GMACs = 13.8466% MACs, 155.09 GFLOPS = 13.8663% FLOPs\n",
      "    (groupnorm_1): GroupNorm(256 = 0.0007% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.015% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(147.58 K = 0.432% Params, 38.65 GMACs = 6.9233% MACs, 77.34 GFLOPS = 6.9151% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(256 = 0.0007% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.015% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(147.58 K = 0.432% Params, 38.65 GMACs = 6.9233% MACs, 77.34 GFLOPS = 6.9151% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (2): VAE_ResidualBlock(\n",
      "    295.68 K = 0.8655% Params, 77.31 GMACs = 13.8466% MACs, 155.09 GFLOPS = 13.8663% FLOPs\n",
      "    (groupnorm_1): GroupNorm(256 = 0.0007% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.015% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(147.58 K = 0.432% Params, 38.65 GMACs = 6.9233% MACs, 77.34 GFLOPS = 6.9151% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(256 = 0.0007% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.015% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(147.58 K = 0.432% Params, 38.65 GMACs = 6.9233% MACs, 77.34 GFLOPS = 6.9151% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (3): Conv2d(147.58 K = 0.432% Params, 9.66 GMACs = 1.7308% MACs, 19.34 GFLOPS = 1.7288% FLOPs, 128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (4): VAE_ResidualBlock(\n",
      "    919.04 K = 2.6901% Params, 60.13 GMACs = 10.7695% MACs, 120.46 GFLOPS = 10.7702% FLOPs\n",
      "    (groupnorm_1): GroupNorm(256 = 0.0007% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0038% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(295.17 K = 0.864% Params, 19.33 GMACs = 3.4616% MACs, 38.67 GFLOPS = 3.4576% FLOPs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(512 = 0.0015% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0075% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(590.08 K = 1.7272% Params, 38.65 GMACs = 6.9233% MACs, 77.33 GFLOPS = 6.9136% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Conv2d(33.02 K = 0.0967% Params, 2.15 GMACs = 0.3846% MACs, 4.31 GFLOPS = 0.3855% FLOPs, 128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (5): VAE_ResidualBlock(\n",
      "    1.18 M = 3.4574% Params, 77.31 GMACs = 13.8466% MACs, 154.85 GFLOPS = 13.8453% FLOPs\n",
      "    (groupnorm_1): GroupNorm(512 = 0.0015% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0075% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(590.08 K = 1.7272% Params, 38.65 GMACs = 6.9233% MACs, 77.33 GFLOPS = 6.9136% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(512 = 0.0015% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0075% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(590.08 K = 1.7272% Params, 38.65 GMACs = 6.9233% MACs, 77.33 GFLOPS = 6.9136% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (6): Conv2d(590.08 K = 1.7272% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7284% FLOPs, 256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (7): VAE_ResidualBlock(\n",
      "    3.67 M = 10.7514% Params, 60.13 GMACs = 10.7695% MACs, 120.36 GFLOPS = 10.7612% FLOPs\n",
      "    (groupnorm_1): GroupNorm(512 = 0.0015% Params, 0 MACs = 0% MACs, 20.97 MFLOPS = 0.0019% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(1.18 M = 3.4544% Params, 19.33 GMACs = 3.4616% MACs, 38.66 GFLOPS = 3.4568% FLOPs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0038% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 6.9074% Params, 38.65 GMACs = 6.9233% MACs, 77.32 GFLOPS = 6.9129% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Conv2d(131.58 K = 0.3852% Params, 2.15 GMACs = 0.3846% MACs, 4.3 GFLOPS = 0.3848% FLOPs, 256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (8): VAE_ResidualBlock(\n",
      "    4.72 M = 13.8207% Params, 77.31 GMACs = 13.8466% MACs, 154.74 GFLOPS = 13.8348% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0038% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 6.9074% Params, 38.65 GMACs = 6.9233% MACs, 77.32 GFLOPS = 6.9129% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0038% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 6.9074% Params, 38.65 GMACs = 6.9233% MACs, 77.32 GFLOPS = 6.9129% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (9): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (10): VAE_ResidualBlock(\n",
      "    4.72 M = 13.8207% Params, 19.33 GMACs = 3.4616% MACs, 38.68 GFLOPS = 3.4587% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (11): VAE_ResidualBlock(\n",
      "    4.72 M = 13.8207% Params, 19.33 GMACs = 3.4616% MACs, 38.68 GFLOPS = 3.4587% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (12): VAE_ResidualBlock(\n",
      "    4.72 M = 13.8207% Params, 19.33 GMACs = 3.4616% MACs, 38.68 GFLOPS = 3.4587% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (13): VAE_AttentionBlock(\n",
      "    1.05 M = 3.0783% Params, 21.47 GMACs = 3.8463% MACs, 42.98 GFLOPS = 3.8425% FLOPs\n",
      "    (groupnorm): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (attention): SelfAttention(\n",
      "      1.05 M = 3.0753% Params, 21.47 GMACs = 3.8463% MACs, 42.97 GFLOPS = 3.8416% FLOPs\n",
      "      (in_proj): Linear(787.97 K = 2.3065% Params, 3.22 GMACs = 0.5769% MACs, 6.44 GFLOPS = 0.576% FLOPs, in_features=512, out_features=1536, bias=True)\n",
      "      (out_proj): Linear(262.66 K = 0.7688% Params, 1.07 GMACs = 0.1923% MACs, 2.15 GFLOPS = 0.192% FLOPs, in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (14): VAE_ResidualBlock(\n",
      "    4.72 M = 13.8207% Params, 19.33 GMACs = 3.4616% MACs, 38.68 GFLOPS = 3.4587% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 6.9074% Params, 9.66 GMACs = 1.7308% MACs, 19.33 GFLOPS = 1.7282% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (15): GroupNorm(1.02 K = 0.003% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0009% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "  (16): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 2.1 MFLOPS = 0.0002% FLOPs)\n",
      "  (17): Conv2d(36.87 K = 0.1079% Params, 150.99 MMACs = 0.027% MACs, 302.02 MFLOPS = 0.027% FLOPs, 512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): Conv2d(72 = 0.0002% Params, 262.14 KMACs = 0% MACs, 557.06 KFLOPS = 0% FLOPs, 8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Encoder FLOPs:1.1185 TFLOPS   MACs:558.329 GMACs   Params:34.1637 M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = encoder\n",
    "batch_size = 1\n",
    "flops, macs, params = calculate_flops(model=encoder, \n",
    "                                    args = [input_image_tensor, encoder_noise],\n",
    "                                    output_as_string=True,\n",
    "                                    output_precision=4)\n",
    "\n",
    "print(\"Encoder FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  49.49 M \n",
      "fwd MACs:                                                               1.2573 TMACs\n",
      "fwd FLOPs:                                                              2.5179 TFLOPS\n",
      "fwd+bwd MACs:                                                           3.7718 TMACs\n",
      "fwd+bwd FLOPs:                                                          7.5536 TFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "VAE_Decoder(\n",
      "  49.49 M = 100% Params, 1.26 TMACs = 100% MACs, 2.52 TFLOPS = 100% FLOPs\n",
      "  (0): Conv2d(20 = 0% Params, 65.54 KMACs = 0% MACs, 147.46 KFLOPS = 0% FLOPs, 4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(18.94 K = 0.0383% Params, 75.5 MMACs = 0.006% MACs, 153.09 MFLOPS = 0.0061% FLOPs, 4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 19.33 GMACs = 1.5373% MACs, 38.68 GFLOPS = 1.5364% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (3): VAE_AttentionBlock(\n",
      "    1.05 M = 2.125% Params, 21.47 GMACs = 1.7081% MACs, 42.98 GFLOPS = 1.7069% FLOPs\n",
      "    (groupnorm): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (attention): SelfAttention(\n",
      "      1.05 M = 2.1229% Params, 21.47 GMACs = 1.7081% MACs, 42.97 GFLOPS = 1.7065% FLOPs\n",
      "      (in_proj): Linear(787.97 K = 1.5922% Params, 3.22 GMACs = 0.2562% MACs, 6.44 GFLOPS = 0.2559% FLOPs, in_features=512, out_features=1536, bias=True)\n",
      "      (out_proj): Linear(262.66 K = 0.5307% Params, 1.07 GMACs = 0.0854% MACs, 2.15 GFLOPS = 0.0853% FLOPs, in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (4): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 19.33 GMACs = 1.5373% MACs, 38.68 GFLOPS = 1.5364% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (5): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 19.33 GMACs = 1.5373% MACs, 38.68 GFLOPS = 1.5364% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (6): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 19.33 GMACs = 1.5373% MACs, 38.68 GFLOPS = 1.5364% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (7): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 19.33 GMACs = 1.5373% MACs, 38.68 GFLOPS = 1.5364% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 10.49 MFLOPS = 0.0004% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 9.66 GMACs = 0.7686% MACs, 19.33 GFLOPS = 0.7677% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (8): Upsample(0 = 0% Params, 0 MACs = 0% MACs, 2.1 MFLOPS = 0.0001% FLOPs, scale_factor=2.0, mode='nearest')\n",
      "  (9): Conv2d(2.36 M = 4.7682% Params, 38.65 GMACs = 3.0745% MACs, 77.32 GFLOPS = 3.0708% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (10): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 77.31 GMACs = 6.149% MACs, 154.74 GFLOPS = 6.1456% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0017% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 38.65 GMACs = 3.0745% MACs, 77.32 GFLOPS = 3.0708% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0017% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 38.65 GMACs = 3.0745% MACs, 77.32 GFLOPS = 3.0708% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (11): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 77.31 GMACs = 6.149% MACs, 154.74 GFLOPS = 6.1456% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0017% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 38.65 GMACs = 3.0745% MACs, 77.32 GFLOPS = 3.0708% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0017% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 38.65 GMACs = 3.0745% MACs, 77.32 GFLOPS = 3.0708% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (12): VAE_ResidualBlock(\n",
      "    4.72 M = 9.5406% Params, 77.31 GMACs = 6.149% MACs, 154.74 GFLOPS = 6.1456% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0017% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(2.36 M = 4.7682% Params, 38.65 GMACs = 3.0745% MACs, 77.32 GFLOPS = 3.0708% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 41.94 MFLOPS = 0.0017% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(2.36 M = 4.7682% Params, 38.65 GMACs = 3.0745% MACs, 77.32 GFLOPS = 3.0708% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (13): Upsample(0 = 0% Params, 0 MACs = 0% MACs, 8.39 MFLOPS = 0.0003% FLOPs, scale_factor=2.0, mode='nearest')\n",
      "  (14): Conv2d(2.36 M = 4.7682% Params, 154.62 GMACs = 12.2981% MACs, 309.27 GFLOPS = 12.2831% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): VAE_ResidualBlock(\n",
      "    1.9 M = 3.8449% Params, 124.55 GMACs = 9.9068% MACs, 249.46 GFLOPS = 9.9077% FLOPs\n",
      "    (groupnorm_1): GroupNorm(1.02 K = 0.0021% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.0067% FLOPs, 32, 512, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(1.18 M = 2.3841% Params, 77.31 GMACs = 6.149% MACs, 154.64 GFLOPS = 6.1416% FLOPs, 512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(512 = 0.001% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0033% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(590.08 K = 1.1923% Params, 38.65 GMACs = 3.0745% MACs, 77.33 GFLOPS = 3.0711% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Conv2d(131.33 K = 0.2654% Params, 8.59 GMACs = 0.6832% MACs, 17.2 GFLOPS = 0.683% FLOPs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (16): VAE_ResidualBlock(\n",
      "    1.18 M = 2.3867% Params, 77.31 GMACs = 6.149% MACs, 154.85 GFLOPS = 6.1502% FLOPs\n",
      "    (groupnorm_1): GroupNorm(512 = 0.001% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0033% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(590.08 K = 1.1923% Params, 38.65 GMACs = 3.0745% MACs, 77.33 GFLOPS = 3.0711% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(512 = 0.001% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0033% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(590.08 K = 1.1923% Params, 38.65 GMACs = 3.0745% MACs, 77.33 GFLOPS = 3.0711% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (17): VAE_ResidualBlock(\n",
      "    1.18 M = 2.3867% Params, 77.31 GMACs = 6.149% MACs, 154.85 GFLOPS = 6.1502% FLOPs\n",
      "    (groupnorm_1): GroupNorm(512 = 0.001% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0033% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(590.08 K = 1.1923% Params, 38.65 GMACs = 3.0745% MACs, 77.33 GFLOPS = 3.0711% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(512 = 0.001% Params, 0 MACs = 0% MACs, 83.89 MFLOPS = 0.0033% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(590.08 K = 1.1923% Params, 38.65 GMACs = 3.0745% MACs, 77.33 GFLOPS = 3.0711% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (18): Upsample(0 = 0% Params, 0 MACs = 0% MACs, 16.78 MFLOPS = 0.0007% FLOPs, scale_factor=2.0, mode='nearest')\n",
      "  (19): Conv2d(590.08 K = 1.1923% Params, 154.62 GMACs = 12.2981% MACs, 309.3 GFLOPS = 12.2845% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): VAE_ResidualBlock(\n",
      "    476.29 K = 0.9624% Params, 124.55 GMACs = 9.9068% MACs, 249.81 GFLOPS = 9.9217% FLOPs\n",
      "    (groupnorm_1): GroupNorm(512 = 0.001% Params, 0 MACs = 0% MACs, 335.54 MFLOPS = 0.0133% FLOPs, 32, 256, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(295.04 K = 0.5962% Params, 77.31 GMACs = 6.149% MACs, 154.65 GFLOPS = 6.1422% FLOPs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(256 = 0.0005% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.0067% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(147.58 K = 0.2982% Params, 38.65 GMACs = 3.0745% MACs, 77.34 GFLOPS = 3.0718% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Conv2d(32.9 K = 0.0665% Params, 8.59 GMACs = 0.6832% MACs, 17.21 GFLOPS = 0.6837% FLOPs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (21): VAE_ResidualBlock(\n",
      "    295.68 K = 0.5975% Params, 77.31 GMACs = 6.149% MACs, 155.09 GFLOPS = 6.1596% FLOPs\n",
      "    (groupnorm_1): GroupNorm(256 = 0.0005% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.0067% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(147.58 K = 0.2982% Params, 38.65 GMACs = 3.0745% MACs, 77.34 GFLOPS = 3.0718% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(256 = 0.0005% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.0067% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(147.58 K = 0.2982% Params, 38.65 GMACs = 3.0745% MACs, 77.34 GFLOPS = 3.0718% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (22): VAE_ResidualBlock(\n",
      "    295.68 K = 0.5975% Params, 77.31 GMACs = 6.149% MACs, 155.09 GFLOPS = 6.1596% FLOPs\n",
      "    (groupnorm_1): GroupNorm(256 = 0.0005% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.0067% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_1): Conv2d(147.58 K = 0.2982% Params, 38.65 GMACs = 3.0745% MACs, 77.34 GFLOPS = 3.0718% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (groupnorm_2): GroupNorm(256 = 0.0005% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.0067% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "    (conv_2): Conv2d(147.58 K = 0.2982% Params, 38.65 GMACs = 3.0745% MACs, 77.34 GFLOPS = 3.0718% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (23): GroupNorm(256 = 0.0005% Params, 0 MACs = 0% MACs, 167.77 MFLOPS = 0.0067% FLOPs, 32, 128, eps=1e-05, affine=True)\n",
      "  (24): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 33.55 MFLOPS = 0.0013% FLOPs)\n",
      "  (25): Conv2d(3.46 K = 0.007% Params, 905.97 MMACs = 0.0721% MACs, 1.81 GFLOPS = 0.072% FLOPs, 128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Decoder FLOPs:2.5179 TFLOPS   MACs:1.2573 TMACs   Params:49.4902 M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder = decoder\n",
    "decoder.to(DEVICE)\n",
    "\n",
    "flops, macs, params = calculate_flops(model=decoder, \n",
    "                                      args = [latents],\n",
    "                                      output_as_string=True,\n",
    "                                      output_precision=4)\n",
    "\n",
    "print(\"Decoder FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  859.52 M\n",
      "fwd MACs:                                                               401.334 GMACs\n",
      "fwd FLOPs:                                                              803.958 GFLOPS\n",
      "fwd+bwd MACs:                                                           1.204 TMACs\n",
      "fwd+bwd FLOPs:                                                          2.4119 TFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "Diffusion(\n",
      "  859.52 M = 100% Params, 401.33 GMACs = 100% MACs, 803.96 GFLOPS = 100% FLOPs\n",
      "  (time_embedding): TimeEmbedding(\n",
      "    2.05 M = 0.2386% Params, 2.05 MMACs = 0.0005% MACs, 4.1 MFLOPS = 0.0005% FLOPs\n",
      "    (linear_1): Linear(410.88 K = 0.0478% Params, 409.6 KMACs = 0.0001% MACs, 819.2 KFLOPS = 0.0001% FLOPs, in_features=320, out_features=1280, bias=True)\n",
      "    (linear_2): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (unet): UNET(\n",
      "    857.46 M = 99.76% Params, 401.28 GMACs = 99.9877% MACs, 803.85 GFLOPS = 99.9868% FLOPs\n",
      "    (encoders): ModuleList(\n",
      "      (0): SwitchSequential(\n",
      "        11.84 K = 0.0014% Params, 47.19 MMACs = 0.0118% MACs, 95.68 MFLOPS = 0.0119% FLOPs\n",
      "        (0): Conv2d(11.84 K = 0.0014% Params, 47.19 MMACs = 0.0118% MACs, 95.68 MFLOPS = 0.0119% FLOPs, 4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1-2): 2 x SwitchSequential(\n",
      "        4.8 M = 0.5586% Params, 26.75 GMACs = 6.6657% MACs, 53.7 GFLOPS = 6.6789% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          2.26 M = 0.2624% Params, 7.55 GMACs = 1.8813% MACs, 15.12 GFLOPS = 1.8805% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(921.92 K = 0.1073% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(409.92 K = 0.0477% Params, 409.6 KMACs = 0.0001% MACs, 819.2 KFLOPS = 0.0001% FLOPs, in_features=1280, out_features=320, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(921.92 K = 0.1073% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          2.55 M = 0.2962% Params, 19.2 GMACs = 4.7845% MACs, 38.58 GFLOPS = 4.7984% FLOPs\n",
      "          (groupnorm): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 840.17 MFLOPS = 0.1045% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            409.92 K = 0.0477% Params, 12.42 GMACs = 3.0935% MACs, 24.96 GFLOPS = 3.1052% FLOPs\n",
      "            (in_proj): Linear(307.2 K = 0.0357% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=320, out_features=960, bias=False)\n",
      "            (out_proj): Linear(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            696.64 K = 0.081% Params, 914.55 MMACs = 0.2279% MACs, 1.83 GFLOPS = 0.2281% FLOPs\n",
      "            (q_proj): Linear(102.4 K = 0.0119% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=False)\n",
      "            (k_proj): Linear(245.76 K = 0.0286% Params, 37.85 MMACs = 0.0094% MACs, 75.69 MFLOPS = 0.0094% FLOPs, in_features=768, out_features=320, bias=False)\n",
      "            (v_proj): Linear(245.76 K = 0.0286% Params, 37.85 MMACs = 0.0094% MACs, 75.69 MFLOPS = 0.0094% FLOPs, in_features=768, out_features=320, bias=False)\n",
      "            (out_proj): Linear(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(821.76 K = 0.0956% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=320, out_features=2560, bias=True)\n",
      "          (linear_geglu_2): Linear(409.92 K = 0.0477% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=1280, out_features=320, bias=True)\n",
      "          (conv_output): Conv2d(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 840.17 MFLOPS = 0.1045% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (3): SwitchSequential(\n",
      "        921.92 K = 0.1073% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs\n",
      "        (0): Conv2d(921.92 K = 0.1073% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (4): SwitchSequential(\n",
      "        15.75 M = 1.832% Params, 15.76 GMACs = 3.9257% MACs, 31.54 GFLOPS = 3.9237% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          6.56 M = 0.763% Params, 5.87 GMACs = 1.4633% MACs, 11.75 GFLOPS = 1.462% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 320, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(1.84 M = 0.2145% Params, 1.89 GMACs = 0.4703% MACs, 3.78 GFLOPS = 0.4696% FLOPs, 320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(819.84 K = 0.0954% Params, 819.2 KMACs = 0.0002% MACs, 1.64 MFLOPS = 0.0002% FLOPs, in_features=1280, out_features=640, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(3.69 M = 0.429% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(205.44 K = 0.0239% Params, 209.72 MMACs = 0.0523% MACs, 420.09 MFLOPS = 0.0523% FLOPs, 320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          9.19 M = 1.069% Params, 9.88 GMACs = 2.4623% MACs, 19.79 GFLOPS = 2.4617% FLOPs\n",
      "          (groupnorm): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            1.64 M = 0.1907% Params, 3.02 GMACs = 0.7525% MACs, 6.05 GFLOPS = 0.7523% FLOPs\n",
      "            (in_proj): Linear(1.23 M = 0.143% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=640, out_features=1920, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            1.8 M = 0.2098% Params, 990.25 MMACs = 0.2467% MACs, 1.98 GFLOPS = 0.2465% FLOPs\n",
      "            (q_proj): Linear(409.6 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=False)\n",
      "            (k_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (v_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(3.28 M = 0.3818% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=640, out_features=5120, bias=True)\n",
      "          (linear_geglu_2): Linear(1.64 M = 0.1907% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=2560, out_features=640, bias=True)\n",
      "          (conv_output): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): SwitchSequential(\n",
      "        17.38 M = 2.0226% Params, 17.43 GMACs = 4.3437% MACs, 34.9 GFLOPS = 4.3412% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          8.2 M = 0.9536% Params, 7.55 GMACs = 1.8814% MACs, 15.11 GFLOPS = 1.8795% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(3.69 M = 0.429% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(819.84 K = 0.0954% Params, 819.2 KMACs = 0.0002% MACs, 1.64 MFLOPS = 0.0002% FLOPs, in_features=1280, out_features=640, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(3.69 M = 0.429% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          9.19 M = 1.069% Params, 9.88 GMACs = 2.4623% MACs, 19.79 GFLOPS = 2.4617% FLOPs\n",
      "          (groupnorm): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            1.64 M = 0.1907% Params, 3.02 GMACs = 0.7525% MACs, 6.05 GFLOPS = 0.7523% FLOPs\n",
      "            (in_proj): Linear(1.23 M = 0.143% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=640, out_features=1920, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            1.8 M = 0.2098% Params, 990.25 MMACs = 0.2467% MACs, 1.98 GFLOPS = 0.2465% FLOPs\n",
      "            (q_proj): Linear(409.6 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=False)\n",
      "            (k_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (v_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(3.28 M = 0.3818% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=640, out_features=5120, bias=True)\n",
      "          (linear_geglu_2): Linear(1.64 M = 0.1907% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=2560, out_features=640, bias=True)\n",
      "          (conv_output): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): SwitchSequential(\n",
      "        3.69 M = 0.429% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs\n",
      "        (0): Conv2d(3.69 M = 0.429% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (7): SwitchSequential(\n",
      "        59.35 M = 6.9045% Params, 14.73 GMACs = 3.671% MACs, 29.48 GFLOPS = 3.6667% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          24.58 M = 2.8603% Params, 5.87 GMACs = 1.4635% MACs, 11.75 GFLOPS = 1.4617% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 819.2 KFLOPS = 0.0001% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(7.37 M = 0.8579% Params, 1.89 GMACs = 0.4703% MACs, 3.78 GFLOPS = 0.4696% FLOPs, 640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(14.75 M = 1.7157% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9391% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(820.48 K = 0.0955% Params, 209.72 MMACs = 0.0523% MACs, 419.76 MFLOPS = 0.0522% FLOPs, 640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          34.76 M = 4.0442% Params, 8.86 GMACs = 2.2074% MACs, 17.73 GFLOPS = 2.2051% FLOPs\n",
      "          (groupnorm): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            6.55 M = 0.7626% Params, 1.85 GMACs = 0.4598% MACs, 3.69 GFLOPS = 0.4592% FLOPs\n",
      "            (in_proj): Linear(4.92 M = 0.5719% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=1280, out_features=3840, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            5.24 M = 0.6101% Params, 1.14 GMACs = 0.2845% MACs, 2.28 GFLOPS = 0.284% FLOPs\n",
      "            (q_proj): Linear(1.64 M = 0.1906% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=False)\n",
      "            (k_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(13.12 M = 1.5261% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=1280, out_features=10240, bias=True)\n",
      "          (linear_geglu_2): Linear(6.55 M = 0.7626% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=5120, out_features=1280, bias=True)\n",
      "          (conv_output): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): SwitchSequential(\n",
      "        65.9 M = 7.667% Params, 16.41 GMACs = 4.089% MACs, 32.84 GFLOPS = 4.0842% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          31.14 M = 3.6228% Params, 7.55 GMACs = 1.8816% MACs, 15.11 GFLOPS = 1.8791% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(14.75 M = 1.7157% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9391% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(14.75 M = 1.7157% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9391% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          34.76 M = 4.0442% Params, 8.86 GMACs = 2.2074% MACs, 17.73 GFLOPS = 2.2051% FLOPs\n",
      "          (groupnorm): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            6.55 M = 0.7626% Params, 1.85 GMACs = 0.4598% MACs, 3.69 GFLOPS = 0.4592% FLOPs\n",
      "            (in_proj): Linear(4.92 M = 0.5719% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=1280, out_features=3840, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            5.24 M = 0.6101% Params, 1.14 GMACs = 0.2845% MACs, 2.28 GFLOPS = 0.284% FLOPs\n",
      "            (q_proj): Linear(1.64 M = 0.1906% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=False)\n",
      "            (k_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(13.12 M = 1.5261% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=1280, out_features=10240, bias=True)\n",
      "          (linear_geglu_2): Linear(6.55 M = 0.7626% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=5120, out_features=1280, bias=True)\n",
      "          (conv_output): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (9): SwitchSequential(\n",
      "        14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs\n",
      "        (0): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (10-11): 2 x SwitchSequential(\n",
      "        31.14 M = 3.6228% Params, 1.89 GMACs = 0.4707% MACs, 3.78 GFLOPS = 0.4701% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          31.14 M = 3.6228% Params, 1.89 GMACs = 0.4707% MACs, 3.78 GFLOPS = 0.4701% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bottleneck): SwitchSequential(\n",
      "      97.04 M = 11.2898% Params, 6.19 GMACs = 1.542% MACs, 12.38 GFLOPS = 1.5401% FLOPs\n",
      "      (0): UNET_ResidualBlock(\n",
      "        31.14 M = 3.6228% Params, 1.89 GMACs = 0.4707% MACs, 3.78 GFLOPS = 0.4701% FLOPs\n",
      "        (groupnorm_feature): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "        (conv_feature): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "        (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "        (conv_merged): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      )\n",
      "      (1): UNET_AttentionBlock(\n",
      "        34.76 M = 4.0442% Params, 2.41 GMACs = 0.6006% MACs, 4.82 GFLOPS = 0.5999% FLOPs\n",
      "        (groupnorm): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-06, affine=True)\n",
      "        (conv_input): Conv2d(1.64 M = 0.1908% Params, 104.86 MMACs = 0.0261% MACs, 209.8 MFLOPS = 0.0261% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (layernorm_1): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention_1): SelfAttention(\n",
      "          6.55 M = 0.7626% Params, 429.92 MMACs = 0.1071% MACs, 859.87 MFLOPS = 0.107% FLOPs\n",
      "          (in_proj): Linear(4.92 M = 0.5719% Params, 314.57 MMACs = 0.0784% MACs, 629.15 MFLOPS = 0.0783% FLOPs, in_features=1280, out_features=3840, bias=False)\n",
      "          (out_proj): Linear(1.64 M = 0.1908% Params, 104.86 MMACs = 0.0261% MACs, 209.72 MFLOPS = 0.0261% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (layernorm_2): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention_2): CrossAttention(\n",
      "          5.24 M = 0.6101% Params, 512.49 MMACs = 0.1277% MACs, 1.03 GFLOPS = 0.1275% FLOPs\n",
      "          (q_proj): Linear(1.64 M = 0.1906% Params, 104.86 MMACs = 0.0261% MACs, 209.72 MFLOPS = 0.0261% FLOPs, in_features=1280, out_features=1280, bias=False)\n",
      "          (k_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "          (v_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "          (out_proj): Linear(1.64 M = 0.1908% Params, 104.86 MMACs = 0.0261% MACs, 209.72 MFLOPS = 0.0261% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (layernorm_3): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear_geglu_1): Linear(13.12 M = 1.5261% Params, 838.86 MMACs = 0.209% MACs, 1.68 GFLOPS = 0.2087% FLOPs, in_features=1280, out_features=10240, bias=True)\n",
      "        (linear_geglu_2): Linear(6.55 M = 0.7626% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=5120, out_features=1280, bias=True)\n",
      "        (conv_output): Conv2d(1.64 M = 0.1908% Params, 104.86 MMACs = 0.0261% MACs, 209.8 MFLOPS = 0.0261% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): UNET_ResidualBlock(\n",
      "        31.14 M = 3.6228% Params, 1.89 GMACs = 0.4707% MACs, 3.78 GFLOPS = 0.4701% FLOPs\n",
      "        (groupnorm_feature): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "        (conv_feature): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "        (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "        (conv_merged): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (residual_layer): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      )\n",
      "    )\n",
      "    (decoders): ModuleList(\n",
      "      (0-1): 2 x SwitchSequential(\n",
      "        49.16 M = 5.72% Params, 3.04 GMACs = 0.7581% MACs, 6.09 GFLOPS = 0.7571% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          49.16 M = 5.72% Params, 3.04 GMACs = 0.7581% MACs, 6.09 GFLOPS = 0.7571% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(5.12 K = 0.0006% Params, 0 MACs = 0% MACs, 819.2 KFLOPS = 0.0001% FLOPs, 32, 2560, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(29.49 M = 3.4313% Params, 1.89 GMACs = 0.4703% MACs, 3.77 GFLOPS = 0.4695% FLOPs, 2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(3.28 M = 0.3814% Params, 209.72 MMACs = 0.0523% MACs, 419.51 MFLOPS = 0.0522% FLOPs, 2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): SwitchSequential(\n",
      "        63.91 M = 7.4357% Params, 6.82 GMACs = 1.6987% MACs, 13.64 GFLOPS = 1.6962% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          49.16 M = 5.72% Params, 3.04 GMACs = 0.7581% MACs, 6.09 GFLOPS = 0.7571% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(5.12 K = 0.0006% Params, 0 MACs = 0% MACs, 819.2 KFLOPS = 0.0001% FLOPs, 32, 2560, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(29.49 M = 3.4313% Params, 1.89 GMACs = 0.4703% MACs, 3.77 GFLOPS = 0.4695% FLOPs, 2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 409.6 KFLOPS = 0.0001% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(14.75 M = 1.7157% Params, 943.72 MMACs = 0.2351% MACs, 1.89 GFLOPS = 0.2348% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(3.28 M = 0.3814% Params, 209.72 MMACs = 0.0523% MACs, 419.51 MFLOPS = 0.0522% FLOPs, 2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Upsample(\n",
      "          14.75 M = 1.7157% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9391% FLOPs\n",
      "          (conv): Conv2d(14.75 M = 1.7157% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9391% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (3-4): 2 x SwitchSequential(\n",
      "        83.93 M = 9.7642% Params, 21.02 GMACs = 5.2386% MACs, 42.06 GFLOPS = 5.2322% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          49.16 M = 5.72% Params, 12.17 GMACs = 3.0312% MACs, 24.34 GFLOPS = 3.0272% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(5.12 K = 0.0006% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 2560, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(29.49 M = 3.4313% Params, 7.55 GMACs = 1.8812% MACs, 15.1 GFLOPS = 1.8782% FLOPs, 2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(14.75 M = 1.7157% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9391% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(3.28 M = 0.3814% Params, 838.86 MMACs = 0.209% MACs, 1.68 GFLOPS = 0.2087% FLOPs, 2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          34.76 M = 4.0442% Params, 8.86 GMACs = 2.2074% MACs, 17.73 GFLOPS = 2.2051% FLOPs\n",
      "          (groupnorm): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            6.55 M = 0.7626% Params, 1.85 GMACs = 0.4598% MACs, 3.69 GFLOPS = 0.4592% FLOPs\n",
      "            (in_proj): Linear(4.92 M = 0.5719% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=1280, out_features=3840, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            5.24 M = 0.6101% Params, 1.14 GMACs = 0.2845% MACs, 2.28 GFLOPS = 0.284% FLOPs\n",
      "            (q_proj): Linear(1.64 M = 0.1906% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=False)\n",
      "            (k_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(13.12 M = 1.5261% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=1280, out_features=10240, bias=True)\n",
      "          (linear_geglu_2): Linear(6.55 M = 0.7626% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=5120, out_features=1280, bias=True)\n",
      "          (conv_output): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): SwitchSequential(\n",
      "        90.48 M = 10.5267% Params, 34.03 GMACs = 8.4784% MACs, 68.07 GFLOPS = 8.4669% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          40.97 M = 4.7668% Params, 10.07 GMACs = 2.5086% MACs, 20.14 GFLOPS = 2.5053% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(3.84 K = 0.0004% Params, 0 MACs = 0% MACs, 2.46 MFLOPS = 0.0003% FLOPs, 32, 1920, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(22.12 M = 2.5735% Params, 5.66 GMACs = 1.4109% MACs, 11.32 GFLOPS = 1.4087% FLOPs, 1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(1.64 M = 0.1908% Params, 1.64 MMACs = 0.0004% MACs, 3.28 MFLOPS = 0.0004% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(14.75 M = 1.7157% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9391% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(2.46 M = 0.2861% Params, 629.15 MMACs = 0.1568% MACs, 1.26 GFLOPS = 0.1566% FLOPs, 1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          34.76 M = 4.0442% Params, 8.86 GMACs = 2.2074% MACs, 17.73 GFLOPS = 2.2051% FLOPs\n",
      "          (groupnorm): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, 32, 1280, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            6.55 M = 0.7626% Params, 1.85 GMACs = 0.4598% MACs, 3.69 GFLOPS = 0.4592% FLOPs\n",
      "            (in_proj): Linear(4.92 M = 0.5719% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=1280, out_features=3840, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            5.24 M = 0.6101% Params, 1.14 GMACs = 0.2845% MACs, 2.28 GFLOPS = 0.284% FLOPs\n",
      "            (q_proj): Linear(1.64 M = 0.1906% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=False)\n",
      "            (k_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(983.04 K = 0.1144% Params, 151.39 MMACs = 0.0377% MACs, 302.78 MFLOPS = 0.0377% FLOPs, in_features=768, out_features=1280, bias=False)\n",
      "            (out_proj): Linear(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 1.64 MFLOPS = 0.0002% FLOPs, (1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(13.12 M = 1.5261% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=1280, out_features=10240, bias=True)\n",
      "          (linear_geglu_2): Linear(6.55 M = 0.7626% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=5120, out_features=1280, bias=True)\n",
      "          (conv_output): Conv2d(1.64 M = 0.1908% Params, 419.43 MMACs = 0.1045% MACs, 839.19 MFLOPS = 0.1044% FLOPs, 1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Upsample(\n",
      "          14.75 M = 1.7157% Params, 15.1 GMACs = 3.7623% MACs, 30.2 GFLOPS = 3.7565% FLOPs\n",
      "          (conv): Conv2d(14.75 M = 1.7157% Params, 15.1 GMACs = 3.7623% MACs, 30.2 GFLOPS = 3.7565% FLOPs, 1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): SwitchSequential(\n",
      "        25.99 M = 3.0237% Params, 26.24 GMACs = 6.5384% MACs, 52.53 GFLOPS = 6.5334% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          16.8 M = 1.9547% Params, 16.36 GMACs = 4.0761% MACs, 32.73 GFLOPS = 4.0717% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(3.84 K = 0.0004% Params, 0 MACs = 0% MACs, 9.83 MFLOPS = 0.0012% FLOPs, 32, 1920, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(11.06 M = 1.2867% Params, 11.32 GMACs = 2.8217% MACs, 22.65 GFLOPS = 2.8173% FLOPs, 1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(819.84 K = 0.0954% Params, 819.2 KMACs = 0.0002% MACs, 1.64 MFLOPS = 0.0002% FLOPs, in_features=1280, out_features=640, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(3.69 M = 0.429% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(1.23 M = 0.143% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.3131% FLOPs, 1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          9.19 M = 1.069% Params, 9.88 GMACs = 2.4623% MACs, 19.79 GFLOPS = 2.4617% FLOPs\n",
      "          (groupnorm): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            1.64 M = 0.1907% Params, 3.02 GMACs = 0.7525% MACs, 6.05 GFLOPS = 0.7523% FLOPs\n",
      "            (in_proj): Linear(1.23 M = 0.143% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=640, out_features=1920, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            1.8 M = 0.2098% Params, 990.25 MMACs = 0.2467% MACs, 1.98 GFLOPS = 0.2465% FLOPs\n",
      "            (q_proj): Linear(409.6 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=False)\n",
      "            (k_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (v_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(3.28 M = 0.3818% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=640, out_features=5120, bias=True)\n",
      "          (linear_geglu_2): Linear(1.64 M = 0.1907% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=2560, out_features=640, bias=True)\n",
      "          (conv_output): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (7): SwitchSequential(\n",
      "        21.89 M = 2.5471% Params, 22.05 GMACs = 5.4933% MACs, 44.13 GFLOPS = 5.4895% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          12.7 M = 1.478% Params, 12.16 GMACs = 3.031% MACs, 24.34 GFLOPS = 3.0278% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(2.56 K = 0.0003% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 1280, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(7.37 M = 0.8579% Params, 7.55 GMACs = 1.8812% MACs, 15.1 GFLOPS = 1.8782% FLOPs, 1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(819.84 K = 0.0954% Params, 819.2 KMACs = 0.0002% MACs, 1.64 MFLOPS = 0.0002% FLOPs, in_features=1280, out_features=640, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(3.69 M = 0.429% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(819.84 K = 0.0954% Params, 838.86 MMACs = 0.209% MACs, 1.68 GFLOPS = 0.2088% FLOPs, 1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          9.19 M = 1.069% Params, 9.88 GMACs = 2.4623% MACs, 19.79 GFLOPS = 2.4617% FLOPs\n",
      "          (groupnorm): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            1.64 M = 0.1907% Params, 3.02 GMACs = 0.7525% MACs, 6.05 GFLOPS = 0.7523% FLOPs\n",
      "            (in_proj): Linear(1.23 M = 0.143% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=640, out_features=1920, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            1.8 M = 0.2098% Params, 990.25 MMACs = 0.2467% MACs, 1.98 GFLOPS = 0.2465% FLOPs\n",
      "            (q_proj): Linear(409.6 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=False)\n",
      "            (k_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (v_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(3.28 M = 0.3818% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=640, out_features=5120, bias=True)\n",
      "          (linear_geglu_2): Linear(1.64 M = 0.1907% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=2560, out_features=640, bias=True)\n",
      "          (conv_output): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): SwitchSequential(\n",
      "        23.53 M = 2.7377% Params, 35.05 GMACs = 8.7331% MACs, 70.14 GFLOPS = 8.7243% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          10.66 M = 1.2397% Params, 10.07 GMACs = 2.5084% MACs, 20.15 GFLOPS = 2.5059% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(1.92 K = 0.0002% Params, 0 MACs = 0% MACs, 4.92 MFLOPS = 0.0006% FLOPs, 32, 960, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(5.53 M = 0.6434% Params, 5.66 GMACs = 1.4109% MACs, 11.33 GFLOPS = 1.4087% FLOPs, 960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(819.84 K = 0.0954% Params, 819.2 KMACs = 0.0002% MACs, 1.64 MFLOPS = 0.0002% FLOPs, in_features=1280, out_features=640, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(3.69 M = 0.429% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(615.04 K = 0.0716% Params, 629.15 MMACs = 0.1568% MACs, 1.26 GFLOPS = 0.1566% FLOPs, 960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          9.19 M = 1.069% Params, 9.88 GMACs = 2.4623% MACs, 19.79 GFLOPS = 2.4617% FLOPs\n",
      "          (groupnorm): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, 32, 640, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            1.64 M = 0.1907% Params, 3.02 GMACs = 0.7525% MACs, 6.05 GFLOPS = 0.7523% FLOPs\n",
      "            (in_proj): Linear(1.23 M = 0.143% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=640, out_features=1920, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            1.8 M = 0.2098% Params, 990.25 MMACs = 0.2467% MACs, 1.98 GFLOPS = 0.2465% FLOPs\n",
      "            (q_proj): Linear(409.6 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=False)\n",
      "            (k_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (v_proj): Linear(491.52 K = 0.0572% Params, 75.69 MMACs = 0.0189% MACs, 151.39 MFLOPS = 0.0188% FLOPs, in_features=768, out_features=640, bias=False)\n",
      "            (out_proj): Linear(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 3.28 MFLOPS = 0.0004% FLOPs, (640,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(3.28 M = 0.3818% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=640, out_features=5120, bias=True)\n",
      "          (linear_geglu_2): Linear(1.64 M = 0.1907% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=2560, out_features=640, bias=True)\n",
      "          (conv_output): Conv2d(410.24 K = 0.0477% Params, 419.43 MMACs = 0.1045% MACs, 839.52 MFLOPS = 0.1044% FLOPs, 640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Upsample(\n",
      "          3.69 M = 0.429% Params, 15.1 GMACs = 3.7623% MACs, 30.2 GFLOPS = 3.7567% FLOPs\n",
      "          (conv): Conv2d(3.69 M = 0.429% Params, 15.1 GMACs = 3.7623% MACs, 30.2 GFLOPS = 3.7566% FLOPs, 640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (9): SwitchSequential(\n",
      "        6.95 M = 0.809% Params, 35.56 GMACs = 8.8604% MACs, 71.33 GFLOPS = 8.8722% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          4.41 M = 0.5127% Params, 16.36 GMACs = 4.076% MACs, 32.75 GFLOPS = 4.0738% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(1.92 K = 0.0002% Params, 0 MACs = 0% MACs, 19.66 MFLOPS = 0.0024% FLOPs, 32, 960, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(2.77 M = 0.3217% Params, 11.32 GMACs = 2.8217% MACs, 22.65 GFLOPS = 2.8174% FLOPs, 960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(409.92 K = 0.0477% Params, 409.6 KMACs = 0.0001% MACs, 819.2 KFLOPS = 0.0001% FLOPs, in_features=1280, out_features=320, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(921.92 K = 0.1073% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(307.52 K = 0.0358% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.3132% FLOPs, 960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          2.55 M = 0.2962% Params, 19.2 GMACs = 4.7845% MACs, 38.58 GFLOPS = 4.7984% FLOPs\n",
      "          (groupnorm): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 840.17 MFLOPS = 0.1045% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            409.92 K = 0.0477% Params, 12.42 GMACs = 3.0935% MACs, 24.96 GFLOPS = 3.1052% FLOPs\n",
      "            (in_proj): Linear(307.2 K = 0.0357% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=320, out_features=960, bias=False)\n",
      "            (out_proj): Linear(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            696.64 K = 0.081% Params, 914.55 MMACs = 0.2279% MACs, 1.83 GFLOPS = 0.2281% FLOPs\n",
      "            (q_proj): Linear(102.4 K = 0.0119% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=False)\n",
      "            (k_proj): Linear(245.76 K = 0.0286% Params, 37.85 MMACs = 0.0094% MACs, 75.69 MFLOPS = 0.0094% FLOPs, in_features=768, out_features=320, bias=False)\n",
      "            (v_proj): Linear(245.76 K = 0.0286% Params, 37.85 MMACs = 0.0094% MACs, 75.69 MFLOPS = 0.0094% FLOPs, in_features=768, out_features=320, bias=False)\n",
      "            (out_proj): Linear(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(821.76 K = 0.0956% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=320, out_features=2560, bias=True)\n",
      "          (linear_geglu_2): Linear(409.92 K = 0.0477% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=1280, out_features=320, bias=True)\n",
      "          (conv_output): Conv2d(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 840.17 MFLOPS = 0.1045% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (10-11): 2 x SwitchSequential(\n",
      "        5.93 M = 0.6898% Params, 31.37 GMACs = 7.8153% MACs, 62.93 GFLOPS = 7.8278% FLOPs\n",
      "        (0): UNET_ResidualBlock(\n",
      "          3.38 M = 0.3935% Params, 12.16 GMACs = 3.0309% MACs, 24.36 GFLOPS = 3.0294% FLOPs\n",
      "          (groupnorm_feature): GroupNorm(1.28 K = 0.0001% Params, 0 MACs = 0% MACs, 13.11 MFLOPS = 0.0016% FLOPs, 32, 640, eps=1e-05, affine=True)\n",
      "          (conv_feature): Conv2d(1.84 M = 0.2145% Params, 7.55 GMACs = 1.8812% MACs, 15.1 GFLOPS = 1.8783% FLOPs, 640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (linear_time): Linear(409.92 K = 0.0477% Params, 409.6 KMACs = 0.0001% MACs, 819.2 KFLOPS = 0.0001% FLOPs, in_features=1280, out_features=320, bias=True)\n",
      "          (groupnorm_merged): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-05, affine=True)\n",
      "          (conv_merged): Conv2d(921.92 K = 0.1073% Params, 3.77 GMACs = 0.9406% MACs, 7.55 GFLOPS = 0.9392% FLOPs, 320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (residual_layer): Conv2d(205.12 K = 0.0239% Params, 838.86 MMACs = 0.209% MACs, 1.68 GFLOPS = 0.2088% FLOPs, 640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): UNET_AttentionBlock(\n",
      "          2.55 M = 0.2962% Params, 19.2 GMACs = 4.7845% MACs, 38.58 GFLOPS = 4.7984% FLOPs\n",
      "          (groupnorm): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-06, affine=True)\n",
      "          (conv_input): Conv2d(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 840.17 MFLOPS = 0.1045% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (layernorm_1): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_1): SelfAttention(\n",
      "            409.92 K = 0.0477% Params, 12.42 GMACs = 3.0935% MACs, 24.96 GFLOPS = 3.1052% FLOPs\n",
      "            (in_proj): Linear(307.2 K = 0.0357% Params, 1.26 GMACs = 0.3135% MACs, 2.52 GFLOPS = 0.313% FLOPs, in_features=320, out_features=960, bias=False)\n",
      "            (out_proj): Linear(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (layernorm_2): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention_2): CrossAttention(\n",
      "            696.64 K = 0.081% Params, 914.55 MMACs = 0.2279% MACs, 1.83 GFLOPS = 0.2281% FLOPs\n",
      "            (q_proj): Linear(102.4 K = 0.0119% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=False)\n",
      "            (k_proj): Linear(245.76 K = 0.0286% Params, 37.85 MMACs = 0.0094% MACs, 75.69 MFLOPS = 0.0094% FLOPs, in_features=768, out_features=320, bias=False)\n",
      "            (v_proj): Linear(245.76 K = 0.0286% Params, 37.85 MMACs = 0.0094% MACs, 75.69 MFLOPS = 0.0094% FLOPs, in_features=768, out_features=320, bias=False)\n",
      "            (out_proj): Linear(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 838.86 MFLOPS = 0.1043% FLOPs, in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (layernorm_3): LayerNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, (320,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_geglu_1): Linear(821.76 K = 0.0956% Params, 3.36 GMACs = 0.8361% MACs, 6.71 GFLOPS = 0.8347% FLOPs, in_features=320, out_features=2560, bias=True)\n",
      "          (linear_geglu_2): Linear(409.92 K = 0.0477% Params, 1.68 GMACs = 0.418% MACs, 3.36 GFLOPS = 0.4174% FLOPs, in_features=1280, out_features=320, bias=True)\n",
      "          (conv_output): Conv2d(102.72 K = 0.012% Params, 419.43 MMACs = 0.1045% MACs, 840.17 MFLOPS = 0.1045% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final): UNET_OutputLayer(\n",
      "    12.16 K = 0.0014% Params, 47.19 MMACs = 0.0118% MACs, 102.25 MFLOPS = 0.0127% FLOPs\n",
      "    (groupnorm): GroupNorm(640 = 0.0001% Params, 0 MACs = 0% MACs, 6.55 MFLOPS = 0.0008% FLOPs, 32, 320, eps=1e-05, affine=True)\n",
      "    (conv): Conv2d(11.52 K = 0.0013% Params, 47.19 MMACs = 0.0118% MACs, 94.39 MFLOPS = 0.0117% FLOPs, 320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Diffusion FLOPs:803.958 GFLOPS   MACs:401.334 GMACs   Params:859.521 M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "diffusion = diffusion\n",
    "diffusion.to(DEVICE)\n",
    "\n",
    "batch_size = 1\n",
    "input_shape = (batch_size, 4, LATENTS_HEIGHT, LATENTS_WIDTH)  # Input shape for the diffusion\n",
    "flops, macs, params = calculate_flops(model=diffusion,\n",
    "                                      args=[latents, context, time_embedding],\n",
    "                                      output_as_string=True,\n",
    "                                      output_precision=4)\n",
    "\n",
    "print(\"Diffusion FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkhanh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
